{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: estimate satisfaction function of a formula from instances of its satisfaction on individual runs at discrete parameter values  \n",
    "\n",
    "Find statistical estimate of satisfaction probability $\\varphi$ as function of uncertain parameters $\\theta$, i.e. of the satisfaction function $f_{\\varphi}(\\theta) = P(\\varphi | M_{\\theta})$.  \n",
    "\n",
    "Given: sample trajectories on a few input points, where we can observe the satisfaction $f_{\\varphi}$.  \n",
    "\n",
    "We want to compute an estimate of $f_{\\varphi}(\\theta *)$ together with a confidence interval for all possible values of $\\theta$.  \n",
    "\n",
    "Bayesian approach: define *Prior* over suitable function space $\\rightarrow$ determine functional form of *likelihood* (probabilistic model of how the actual observations depend on the value of the uncertain quantity) $\\rightarrow$ approximate *posterior* distribution over functions to get the estimate  \n",
    "Here: use **Gaussian Processes** (flexible, non-parametric class of distributions; uncertainty quantification).  \n",
    "\n",
    "\n",
    "Use **Gaussian Process Classification** to estimate the satisfaction function, because we have true/false labels per input point (= classification). Prior can be combined with likelihood models for the observations in a Bayesian fashion to yield a joint posterior.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "\n",
    "import math\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.special import erf \n",
    "# scipy gives upper triangular matrix, numpy lower\n",
    "from scipy.linalg import cholesky\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel  \n",
    "\n",
    "Use GP as prior over smooth functions. A sample of a GP is a random function.  \n",
    "\n",
    "Popular kernel: **squared exponential** (or radial basis): $k(x,x')= \\sigma^2 exp(- \\frac{(x-x')^2}{2\\lambda^2}) $   \n",
    "\n",
    "We set a zero-mean Gaussian prior for f: $p(f|X) = \\mathcal{N}(f|0,K)$  \n",
    "\n",
    "___  \n",
    "\n",
    "\n",
    "<!--(We place a GP prior over the latent function $f(x)$ and then squash it to obtain the prior on $\\pi(x) = p(y=1|x) = \\phi(f(x))$.  \n",
    "Squash it with: *probit* transformation (cdf of normal distribution, $\\Phi(z) = \\int^z_{-\\inf} \\mathcal{N}(x|0,1)dx$).) -->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_rbf(x, y, param):\n",
    "    \"\"\" Radial Basis Function Kernel \n",
    "    \n",
    "    Args:\n",
    "        x: First input vector of kernel (N,1)\n",
    "        y: Second input vector of kernel (N,1)\n",
    "        param: Hyperparameter of kernel: scale factor variance and lengthscale ell\n",
    "        \n",
    "    Returns:\n",
    "        Covariance matrix of each pairwise combination of set of points\n",
    "    \"\"\"\n",
    "    variance = param['var']\n",
    "    lengthscale = param['ell']\n",
    "    # Euclidean distance between points\n",
    "    eucdist = np.sum(x**2,1).reshape(-1,1) + np.sum(y**2,1) - 2*np.dot(x, y.T)\n",
    "    return variance * np.exp(-0.5 * eucdist * 1/(lengthscale**2))\n",
    "\n",
    "\n",
    "def kernel_linear(x, y, param):\n",
    "    \"\"\" Linear Kernel\n",
    "    \n",
    "    Args:\n",
    "        x: First input vector of kernel (N,1)\n",
    "        y: Second input vector of kernel (N,1)\n",
    "        param: Hyperparameter of kernel: scale factor variance, variance_b and offset off\n",
    "        \n",
    "    Returns: \n",
    "        Covariance matrix of each pairwise combination of set of points\n",
    "    \"\"\"\n",
    "    variance = param['var']\n",
    "    variance_b = param['var_b']\n",
    "    offset = param['off']\n",
    "    return variance_b + variance * np.dot((x-offset), (y-offset).T)\n",
    "\n",
    "\n",
    "\n",
    "# define default hyperparameters for all kernels\n",
    "params = {'var': 0.1,\n",
    "          'ell': 1,        \n",
    "          'var_b': 1,\n",
    "          'off': 1}\n",
    "\n",
    "\n",
    "# TODO: optimize hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Likelihood model**  \n",
    "Observations are made through *boolean* evaluations of a formula over individual trajectories at some parameter values. It is not possible to directly apply Gaussian observation noise, therefore a closed form solution cannot be found, only an approximation of the posterior. The satisfaction of a formula $\\varphi$ over a trajectory generated from a specific parameter value $\\theta$ is a Bernoulli random variable with success probability $f_{\\varphi}(\\theta)$. We can map this probability to the real numbers with the *inverse probit transformation*:  \n",
    "\n",
    "$\\psi (f) = g \\Leftrightarrow \\int_{-\\infty}^g \\mathcal{N} (0,1) ~ \\forall f \\in [0,1], ~ g \\in \\mathbb{R}$   \n",
    "\n",
    "cdf of normal distribution, $\\Phi(z) = \\int^z_{-\\inf} \\mathcal{N}(x|0,1)dx$  \n",
    "\n",
    "\n",
    "**Inference problem**: We have *D* binary evaluations of satisfaction at each of $P$ parameter values. At each parameter value, these evaluations represent individual draws from the same *Bernoulli* distribution with success probability $f_{\\varphi}(\\theta)$. The transform of this success probability is a smooth function over the (unknown) parameters and is assigned a GP prior. The *overall joint probability* of observations $O$ and of the satisfaction function would be:  \n",
    "\n",
    "$p(O,f_{\\varphi}(\\theta)) = GP ( \\psi (f_{\\varphi}(\\theta))) \\prod^D \\prod^P \\text{Bernoulli} (O_{ij} | f_{\\varphi}(\\theta_j))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Posterior**  \n",
    "Computing the posterior introduces an *approximation* (non-Gaussian likelihood makes integral intractable) $\\rightarrow$ use **Expectation Propagation** algorithm to efficiently compute the approximate posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Inference\n",
    "\n",
    "2 steps:  \n",
    "- compute distribution of latent variable corresponding to a test case: $p(f_*|X,y,x_*) = \\int p(f_*|X,x_*,f) p(f|X,y) df$, where $p(f|X,y) = p(y|f)p(f|X)/p(y|X)$ is the posterior over the latent variables      \n",
    "\n",
    "   \n",
    "     \n",
    "- use this distribution over latent $f_*$ to produce probabilistic prediction: $\\overline{x}_* = p(y_*=1|X,y,x_*) = \\int \\sigma(f_*)p(f_*|X,y,x_*)df$   \n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Propagation\n",
    "\n",
    "**EP** computes a Gaussian approximation to probabilistic models of the form $p(x|y) = p_0(x) \\prod_i t_i(y_i,x_i)$ ($p_0$ is multivariate Gaussian distribution $\\rightarrow$ Prior, and $t_i$ can be general univariate distribution $\\rightarrow$ non-Gaussian observation likelihood)  \n",
    "The likelihood terms are replaced by univariate Gaussian terms: $q(x|y) = p_0(x) \\prod_i \\tilde{t_i} (y_i,x_i)$\n",
    "\n",
    "___\n",
    "\n",
    "**Rasmussen**:  \n",
    "\n",
    "Posterior given by Bayes rule as product of normalization term, prior and likelihood: $p(f|X,y) = \\frac{1}{Z} p(f|X) \\prod p(y_i|f_i)$  \n",
    "Prior $p(f|X)$ is Gaussian, Likelihood factorizes over training cases  \n",
    "Normalization term = marginal likelihood: $Z = p(y|X) = \\int p(f|X) \\prod p(y_i|f_i) df$  \n",
    "\n",
    "Probit likelihood for binary classification: $p(y_i|f_i) = \\Phi(f_iy_i)$ makes posterior intractable  \n",
    "$\\rightarrow$ approximate by local likelihood approximation (unnormalized Gaussian function in latent variable $f_i$): $p(y_i|f_i) \\approx t_i ( f_i|\\tilde{Z}_i,\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2) = \\tilde{Z}_i \\mathcal{N}(f_i|\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2)$  \n",
    "\n",
    "Product of independent local likelihoods $t_i$: $\\prod t_i(f_i| \\tilde{Z}_i,\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2) = \\mathcal{N}(\\tilde{\\mu},\\tilde{\\Sigma}) \\prod \\tilde{Z}_i$, where $\\tilde{\\mu}$ is vector of $\\tilde{\\mu}_i$ and $\\tilde{\\Sigma}$ is diagonal with $\\tilde{\\Sigma}_{ii} = \\tilde{\\sigma}^2_i$.  \n",
    "\n",
    "Approximate posterior $p(f|X,y)$ by: $q(f|X,y) \\overset{\\Delta}{=} \\frac{1}{Z_{EP}} p(f|X) \\prod t_i(f_i| \\tilde{Z}_i,\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2) = \\mathcal{N}(\\mu,\\Sigma)$ [3.53] with $Z_{EP}=q(y|X)$ (approximation to normalizing term Z from previous eq.), $\\mu=\\Sigma\\tilde{\\Sigma}^{-1}\\tilde{\\mu}$ and $\\Sigma=(K^{-1}+\\tilde{\\Sigma}^{-1})^{-1}$  \n",
    "\n",
    "How do we choose parameter of local approximating distributions $t_i$? Minimize Kullback-Leibler divergence between posterior and its approximation. Update $t_i$ approximations sequentially. Start from current approximate posterior, leave out current $t_i$ ($\\rightarrow$ cavity distribution; Combine prior and local likelihood approximations into cavity distribution: $q_{-i}(f_i) \\propto \\int p(f|X) \\prod_{j\\neq i} t_j (f_j|\\tilde{Z}_j, \\tilde{\\mu}_j, \\tilde{\\sigma}_j^2) df_j$, either by explicitly multiplying out the terms, or by removing approximate likelihood i from the approximate posterior in 3.53). Combine cavity with exact likelihood to get desired (non-Gaussian) marginal. Choose Gaussian approximation to this non-Gaussian marginal and then compute the $t_i$ which makes posterior have the desired marginal. Iterate these steps until convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### 2) Perform smoothed model checking (SMC 65)\n",
    "\n",
    "getAnalyticApproximation(data, parameters, options)  \n",
    "-> optimize hyperparameters for rbf kernel or take default ones  \n",
    "-> doTraining = probit gp regression  \n",
    "   -> expectationPropagation\n",
    "   \n",
    "then return performSmoothedModelChecking(approx, parameters, options) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for EP  \n",
    "\n",
    "**Marginal moments** $\\mu$ and $\\sigma^2$  \n",
    "\n",
    "\n",
    "\n",
    "**Rasmussen 3.53:**. \n",
    "\n",
    "$q(f|X,y) \\overset{\\Delta}{=} \\frac{1}{Z_{EP}} p(f|X) \\prod t_i(f_i| \\tilde{Z}_i,\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2) = \\mathcal{N}(\\mu,\\Sigma)$   \n",
    "\n",
    "with $Z_{EP}=q(y|X)$,   \n",
    "\n",
    "$\\mu=\\Sigma\\tilde{\\Sigma}^{-1}\\tilde{\\mu}$, $\\tilde{\\Sigma}$ is diagonal with $\\tilde{\\Sigma}_{ii} = \\tilde{\\sigma}_i^2$   \n",
    "\n",
    "$\\Sigma=(K^{-1}+\\tilde{\\Sigma}^{-1})^{-1}$   \n",
    "\n",
    "\n",
    "\n",
    "**Here:**  \n",
    "\n",
    "\n",
    "! Attention: computation of cholesky(A) may fail when A is not PD (for large amplitudes) --> add another +I for computational stability?    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(Note: Cholesky returns $L'$ for $A = L * L' $)    \n",
    "\n",
    "$L = (cholesky({LC}' * (\\tilde{\\tau} * {LC}) + I))'$  \n",
    "\n",
    "$L * W = LC' \\rightarrow$ Solve for $W$: $W = L^{-1} * LC'$   \n",
    "\n",
    "$diagV = diag(W' * W)$  \n",
    "\n",
    "$m = W' * (W * \\tilde{v})$  \n",
    "\n",
    "$logdet = -2 * \\sum \\log(diag(L)) + 2 * \\sum \\log(diag(LC))$  \n",
    "\n",
    "$logZappx = \\frac{1}{2} (m' * \\tilde{v} + logdet)$\n",
    "\n",
    "\n",
    "\n",
    "Note:   \n",
    "$\\tilde{v} = \\tilde{\\mu} \\tilde{\\sigma}^{-2} = \\tilde{\\mu} * \\tilde{\\tau} $  \n",
    "$\\tilde{\\tau} = \\tilde{\\sigma}^{-2}$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_moments(Term, gauss_LC, gauss_LC_t):\n",
    "    \"\"\"\n",
    "    Computes marginal moments\n",
    "    \n",
    "    Args:\n",
    "        Term: v_tilde, tau_tilde (datapoints, 2)\n",
    "        gauss_LC:\n",
    "        gauss_LC_t: \n",
    "        \n",
    "    Returns:\n",
    "        logZappx: \n",
    "        gauss_m: mu (datapoints,1)\n",
    "        gauss_diagV: diagonal of sigma^2 (datapoints,1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # A = LC' * (tau_tilde * gauss_LC) + I \n",
    "    #print(\"t:\", Term[:,1])\n",
    "    tmp = np.multiply(Term[:,1], gauss_LC)\n",
    "    A = np.matmul(gauss_LC_t, tmp) + 1 * np.eye(datapoints)\n",
    "    #print(\"A:\", A)\n",
    "    #print(\"Eig:\", np.linalg.eigvalsh(A))\n",
    "    gauss_L = cholesky(A).T  \n",
    "\n",
    "    # W = L\\LC' -> Solve L*W = LC'\n",
    "    gauss_W = np.linalg.solve(gauss_L, gauss_LC_t)\n",
    "    gauss_diagV = np.diagonal(np.matmul(gauss_W.T, gauss_W)).reshape(-1,1)\n",
    "    \n",
    "    # m = W'*(W * v_tilde)\n",
    "    tmp = np.matmul(gauss_W, Term[:,0])\n",
    "    gauss_m = np.matmul(gauss_W.T, tmp).reshape(-1,1)\n",
    "\n",
    "    # logdet = -2*sum(log(diag(L))) + 2*sum(log(diag(LC)))\n",
    "    logdet = -2*np.sum(np.log(np.diagonal(gauss_L))) # + 2*np.sum(np.log(np.diag(gauss_LC))) (das ist schon logdet_LC)\n",
    "    logdet += logdet_LC\n",
    "\n",
    "    # logZappx = 1/2(m' * v_tilde + logdet)\n",
    "    logZappx = 0.5 * (np.dot(gauss_m.T, Term[:,0]) + logdet)\n",
    "\n",
    "    return logZappx, gauss_m, gauss_diagV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Gauss–Hermite_quadrature  \n",
    "\n",
    "**Gauss-Hermite quadrature** is a form of Gaussian quadrature for approximating the value of integrals of the following kind:  \n",
    "\n",
    "$ \\int_{-\\infty}^{+\\infty} e^{-x^2} f(x) dx \\approx \\sum_{i=1}^n w_i f(x_i)  $  \n",
    "\n",
    "where $n$ is the number of sample points used (here: nodes). The $x_i$ are the roots of the physicists' version of the Hermite polynomial $H_n(x)$ and the associated weights $w_i$ are given by:  \n",
    "\n",
    "$ w_i = \\frac{ 2^{n-1} n! \\sqrt{\\pi}}{n^2 [H_{n-1}(x_i)]^2}$   \n",
    "\n",
    "\n",
    "Binary classification: determining moments of tilted distribution requires solving only 1-dimensional integrals; assuming probit likelihood functions $\\rightarrow$ univariate integrals can be computed efficiently without quadrature. But here: need quadrature because we have multiple observations per input point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gausshermite(nodes):\n",
    "    \"\"\"\n",
    "    Gauss-Hermite \n",
    "    https://indico.frib.msu.edu/event/15/attachments/40/157/Gaussian_Quadrature_Numerical_Recipes.pdf\n",
    "    \n",
    "    Approximate integral of a formula by the sum of its functional values at some points\n",
    "    \n",
    "    Args:\n",
    "        nodes: number of Gauss-Hermite nodes (96,1)\n",
    "        \n",
    "    Returns:\n",
    "        x0: abscissas (96,1)\n",
    "        w0: weights (96,1)\n",
    "    \"\"\"\n",
    "\n",
    "    x0 = np.zeros((nodes, 1))\n",
    "    w0 = np.zeros((nodes, 1))\n",
    "    m = int((nodes+1)/2)\n",
    "    z,pp,p1,p2,p3 = 0,0,0,0,0\n",
    "    \n",
    "    for i in range(m):\n",
    "        if i==0:\n",
    "            z = np.sqrt(2*nodes+1) - 1.85575 * ((2*nodes+1)**(-0.166667))\n",
    "        elif i==1:\n",
    "            z = z - 1.14 * (nodes**0.426) / z\n",
    "        elif i==2:\n",
    "            z = 1.86 * z - 0.86 * x0[0]\n",
    "        elif i==3:\n",
    "            z = 1.91 * z - 0.91 * x0[1]\n",
    "        else:\n",
    "            z = 2.0 * z - x0[i - 2]\n",
    "\n",
    "        for its in range(10):\n",
    "            p1 = 1/np.sqrt(np.sqrt(np.pi))\n",
    "            p2 = 0\n",
    "            for j in range(1,nodes+1):\n",
    "                p3=p2\n",
    "                p2=p1\n",
    "                a = z*np.sqrt(2/j)*p2\n",
    "                b = np.sqrt((j-1)/j)*p3\n",
    "                p1=a-b\n",
    "            pp=np.sqrt(2*nodes)*p2\n",
    "            z1=z\n",
    "            z=z1-p1/pp\n",
    "            if np.abs(z-z1)<2.2204e-16:\n",
    "                break\n",
    "\n",
    "        x0[i] = z\n",
    "        x0[nodes-1-i] = -z\n",
    "        w0[i] = 2/(pp*pp)\n",
    "        w0[nodes-1-i] = w0[i]\n",
    "\n",
    "    w0 = np.divide(w0, np.sqrt(np.pi))\n",
    "    x0 = np.multiply(x0, np.sqrt(2))\n",
    "    x0 = np.sort(x0, axis=None).reshape(-1,1)\n",
    "    \n",
    "    return x0, w0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute **new posterior marginal moments** $\\hat{\\mu}$ and $\\hat{\\sigma}^2$   \n",
    "\n",
    "Find new Gaussian marginal which best approximates the product of the cavity distribution and the exact likelihood $\\hat{q}(f_i) \\overset{\\Delta}{=} \\hat{Z}_i ~ \\mathcal{N}(\\hat{\\mu}_i, \\hat{\\sigma}^2_i) \\simeq q_{-i} (f_i) p (y_i | f_i) $.  \n",
    "\n",
    "It is well known that distribution $q(x)$ which minimizes KL$(p(x)||q(x))$ is the one whose first and second moments match that of $p(x)$. <!--$\\hat{q}(f_i)$ is unnormalized, so choose additionally the condition that zero-th moments (normalizing constants) should match when choosing the parameters of $\\hat{q}(f_i)$ to match the right-hand side of above equation.-->  \n",
    "Derivation of moments is complicated (see Appendix 3.9). Desired posterior marginal moments are:  \n",
    "\n",
    "**Rasmussen 3.58:**  \n",
    "\n",
    "$ \\hat{Z} = \\Phi (z)$  \n",
    "\n",
    "$ \\hat{\\mu} = \\mu_{-i} + \\frac{y ~ \\sigma^2_{-i} \\mathcal{N}(z)} { \\Phi(z) \\sqrt{1 + \\sigma^2_{-i}}} $  \n",
    "\n",
    "$ \\hat{\\sigma}^2 = \\sigma^2_{-i} - \\frac{ \\sigma^4_{-i} \\mathcal{N}(z)} {(1 + \\sigma^2_{-i}) \\Phi (z) } (z + \\frac{\\mathcal{N}(z)} {\\Phi (z)} ) $,  \n",
    "\n",
    "\n",
    "where $z = \\frac{y ~ \\mu_{-i}} { \\sqrt{1 + \\sigma^2_{-i}} } $  \n",
    "\n",
    "\n",
    "Here:  \n",
    "\n",
    "$G = \\text{logprobitpow}((\\sigma_{-i} * xGH + \\mu_{-i}), p, q) + logwGH'$, $G = G - \\max(G)$ for each datapoint   \n",
    "\n",
    "**Gauss-Hermite** to match distribution https://www.wouterdenhaan.com/numerical/integrationslides.pdf \n",
    "Get $n$ nodes ($xGH$) and weights ($logwGH$) from function *gausshermite*. Expectation of normally distributed variable: $E[h(y)]$ with $y \\sim \\mathcal{N}(\\mu,\\sigma^2)$.  \n",
    "Calculate $\\int_{-\\infty}^{\\infty} \\frac{1}{\\sigma \\sqrt{2 \\pi}} h(y) \\exp(- \\frac{(y-\\mu)^2}{2\\sigma^2})dy$  \n",
    "$\\rightarrow$ do a trick with change of variables and transformation, then approximation is:  \n",
    "\n",
    "$E[h(y)] \\approx \\sum_{i=1}^n \\frac{1}{\\sqrt{\\pi}} w_i h(\\sqrt{2} \\sigma x_i + \\mu)$\n",
    "\n",
    "$\\rightarrow$ this relates to $ \\text{logprobitpow}((\\sigma_{-i} * xGH + \\mu_{-i}), p, q) + logwGH'$, because nodes $x_i$ are already multiplied by $\\sqrt{2}$ and weights $w_i$ are already divided by $\\sqrt{\\pi}$ in *gausshermite*. Since we're taking the logarithm, we have $\\log x \\cdot y = \\log x + \\log y$, so $+ logwGH$ in $G$ instead of $\\cdot w_i$.   \n",
    "\n",
    "But: Why do we take maximum then instead of summing the values?  \n",
    "\n",
    "\n",
    "$logZ = maxG + \\log(\\sum e^G)$ (sum over rows, for each datapoint)  \n",
    "\n",
    "Moments:  \n",
    "\n",
    "$\\hat{\\mu} = \\mu_{-i} + \\Delta_m \\rightarrow \\Delta_m = \\frac{\\sigma_{-i} * (e^G * xGH)}{\\sum e^G} $  \n",
    "\n",
    "$\\hat{\\sigma}^2 = \\frac{\\sigma_{-i}^2 * (e^G * xGH^2)}{\\sum e^G} - \\Delta_m^2$  \n",
    "\n",
    "$logZ = \\max(G) + \\log(\\sum \\exp(G - \\max(G))) = \\log \\sum \\exp(G)$ is smooth approximation to get largest element of $G$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussHermiteNQ(FuncPar_p, FuncPar_q, cav_m, cav_v, xGH, logwGH):\n",
    "    \"\"\"\n",
    "    Gauss-Hermite numerical quadrature for moment computation\n",
    "    \n",
    "    Args:\n",
    "        FuncPar_p: number of runs satisfying property for each parameter value (input) (datapoints,1)\n",
    "        FuncPar_q: number of runs not satisfying property (datapoints,1)\n",
    "        cav_m: cavity mean mu_-i\n",
    "        cav_v: cavity variance sigma^2_-i\n",
    "        xGH: abscissas (Gauss-Hermite)\n",
    "        logwGH: weights (Gauss-Hermite)\n",
    "        \n",
    "    Returns:\n",
    "        logZ: largest element of expectation of normally distributed variable?\n",
    "        Cumul: mu_hat, sigma^2_hat (datapoints,2)\n",
    "    \"\"\"\n",
    "    \n",
    "    Nnodes = len(xGH)\n",
    "    \n",
    "    # sigma_-i\n",
    "    stdv = np.sqrt(cav_v).reshape(-1,1)\n",
    "\n",
    "    # HIER PROBLEM: Dadurch dass stdv von cavity gerechnet wird & cavity variance auch negativ sein kann,\n",
    "    # ist stdv nicht für alle Werte definiert -> dadurch cholesky in marginal_moments = 2I\n",
    "    Y = np.matmul(stdv, xGH.reshape(1,-1)) + numpy.matlib.repmat(cav_m, 1, Nnodes)\n",
    "        \n",
    "    G = np.array(logprobitpow(Y, FuncPar_p, FuncPar_q) + numpy.matlib.repmat(logwGH.T, datapoints, 1))\n",
    "        \n",
    "    # maximum of each row (input value) over all 96 nodes\n",
    "    maxG = G.max(axis=1).reshape(-1,1)\n",
    "    # subtract maximum value\n",
    "    G = G - np.matlib.repmat(maxG, 1, 96)\n",
    "    # exponential value\n",
    "    expG = np.exp(G)\n",
    "    # denominator (row sum)\n",
    "    denominator = expG.sum(axis=1).reshape(-1,1)\n",
    "    logdenominator = np.log(denominator)\n",
    "    logZ = maxG + logdenominator\n",
    "    \n",
    "    Cumul = np.zeros((len(FuncPar_p), 2))\n",
    "\n",
    "\n",
    "    # deltam = stdv * (expG * xGH) / denominator\n",
    "    deltam = np.divide(np.multiply(stdv, np.matmul(expG, xGH)), denominator)\n",
    "\n",
    "    # mu_hat = mu_-i + deltam    \n",
    "    Cumul[:,0] = (cav_m + deltam).reshape(-1)\n",
    "    \n",
    "    xGH2 = xGH**2\n",
    "    deltam2 = deltam**2\n",
    "\n",
    "    # sigma^2_hat\n",
    "    Cumul[:,1] = (np.divide(np.multiply(cav_v, np.matmul(expG, xGH2)), denominator) - deltam2).reshape(-1)\n",
    "        \n",
    "    return logZ, Cumul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute **cavity parameters** $\\mu_{-i}$ and $\\sigma^2_{-i}$   \n",
    "\n",
    "**Rasmussen 3.56:**   \n",
    "\n",
    "\n",
    "$cav_m = \\mu_{-i} = \\sigma_{-i}^2 \\cdot ( \\frac{\\mu}{\\sigma^2} - \\frac{\\tilde{\\mu}}{\\tilde{\\sigma}^2} )$   \n",
    "\n",
    "\n",
    "\n",
    "$cav_v =  \\sigma_{-i}^2 = \\frac{1}{\\sigma^{-2} - \\tilde{\\sigma}^{-2}}  $   \n",
    "\n",
    "\n",
    "**Here:** $diagV = \\sigma^2$ and $\\tilde{\\tau} = \\tilde{\\sigma}^{-2}$ and $\\tilde{v} = \\tilde{\\mu} \\tilde{\\sigma}^{-2}$; transforming the equations shows that they're equal:      \n",
    "\n",
    "$cav_m = \\frac{m + (- \\tilde{v} \\cdot diagV) }{1 + (- \\tilde{\\tau} \\cdot diagV)} = \\frac{ \\mu - \\tilde{\\sigma}^{-2} \\tilde{\\mu} \\sigma^2}{1 - \\tilde{\\sigma}^{-2} \\sigma^2} $   \n",
    "\n",
    "\n",
    "$cav_{diagV} = \\frac{diagV}{1 + (- \\tilde{\\tau} * diagV)} = \\frac{1}{diagV^{-1} - \\tilde{\\tau}} = \\frac{1}{\\sigma^{-2} - \\tilde{\\sigma}^{-2}}$   \n",
    "\n",
    "\n",
    "The cavity distribution combines the prior and the local likelihood approximations; afterwards, it is combined with the exact likelihood for case $i$. To do so, we remove the approximate likelihood $i$ from the approximate posterior by dividing the marginal with the approximate term $t_i$.  \n",
    "$q_{-i}(x) = \\frac{q(x)}{\\tilde{\\tau}_i(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cavities(gauss_diagV, gauss_m, Term):\n",
    "    \"\"\"\n",
    "    Compute cavity distribution by removing the effect of a single factor from q\n",
    "    \n",
    "    Args:\n",
    "        gauss_diagV: sigma^2\n",
    "        gauss_m: mu\n",
    "        Term: v_tilde, tau_tilde (datapoints,2)\n",
    "        \n",
    "    Returns:\n",
    "        cav_m: cavity mean mu_-i\n",
    "        cav_diagV: cavity variance sigma^2_-i\n",
    "    \"\"\"\n",
    "    \n",
    "    # s = 1 / (1 + -tau_tilde * diagV)\n",
    "    s = np.divide(1, (1 + np.multiply(-Term[:,1].reshape(-1,1), gauss_diagV)))\n",
    "\n",
    "    # cav_diagV = s * diagV\n",
    "    cav_diagV = np.multiply(s, gauss_diagV)\n",
    "    \n",
    "    # cav_m = s * (m + (-v_tilde * diagV))\n",
    "    cav_m = np.multiply(s, (gauss_m + np.multiply(-Term[:,0].reshape(-1,1), gauss_diagV)))\n",
    "    \n",
    "    return cav_m, cav_diagV\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update **site parameters** $\\tilde{v}$ and $\\tilde{\\tau}$ with new posterior marginal moments $\\hat{\\mu}$ and $\\hat{\\sigma}^2$.  \n",
    "\n",
    "Final step is to compute the parameters of the approximation $t_i$ which achieves a match with the desired moments. In particular, the product of the cavity distribution and the local approximation must have the desired moments.  \n",
    "\n",
    "\n",
    "**Rasmussen 3.59**   \n",
    "\n",
    "$\\tilde{\\mu}_i = \\tilde{\\sigma}_i^2 ( \\hat{\\sigma}_i^{-2} \\hat{\\mu}_i - \\sigma_{-i}^{-2} \\mu_{-i})$  \n",
    "\n",
    "$\\tilde{\\sigma}_i^2 = (\\hat{\\sigma}_i^{-2} - \\sigma_{-i}^{-2})^{-1}$  \n",
    "\n",
    "\n",
    "**Here**: just simple transformation  \n",
    "\n",
    "\n",
    "$\\tilde{v} = \\hat{\\sigma}_i^{-2} \\hat{\\mu}_i - \\sigma_{-i}^{-2} \\mu_{-i} = \\tilde{\\sigma}_i^{-2} \\tilde{\\mu}_i$  \n",
    "\n",
    "$\\tilde{\\tau} = 1 / \\hat{\\sigma}_i^2 - 1 / \\sigma_{-i}^2 = \\tilde{\\sigma}_i^{-2}$   \n",
    "\n",
    "$logZterms = logZ + \\frac{1}{2} * (\\frac{\\mu_{-i}^2}{\\sigma_{-i}^2} + \\log(\\sigma_{-i}^2) - \\frac{\\hat{\\mu}^2}{\\hat{\\sigma}^2} + \\log(\\hat{\\sigma}^2))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ep_update(cav_diagV, cav_m, Term, eps_damp, gauss_LikPar_p,\n",
    "              gauss_LikPar_q, gauss_xGauss, gauss_logwGauss):\n",
    "    \"\"\"\n",
    "    Update site parameters\n",
    "    \n",
    "    Args:\n",
    "        cav_diagV: cavity variance sigma^2_-i\n",
    "        cav_m: cavity mean mu_-i\n",
    "        Term: v_tilde, tau_tilde (datapoints,2)\n",
    "        eps_damp: 0.5\n",
    "        gauss_LikPar_p: number of runs satisfying property for each parameter (datapoints,1)\n",
    "        gauss_LikPar_q: number of runs not satisfying property (datapoints,1)\n",
    "        gauss_xGauss: abscissas of Gauss-Hermite\n",
    "        gauss_logwGauss: weights of Gauss-Hermite\n",
    "        \n",
    "    Returns:\n",
    "        TermNew: updated v_tilde, tau_tilde (datapoints,2)\n",
    "        logZterms:\n",
    "        logZ:\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Cumul = [mu_hat, sigma^2_hat]    \n",
    "    # Evaluate new approximation q_hat(x) by setting the sufficient statistics equal to that of probit*cavity\n",
    "    logZ, Cumul = GaussHermiteNQ(gauss_LikPar_p, gauss_LikPar_q, cav_m, cav_diagV, gauss_xGauss, gauss_logwGauss)\n",
    "    \n",
    "    \n",
    "    # m2 = mu_-i ^2\n",
    "    m2 = cav_m**2\n",
    "    # loV = log(sigma_-i^2)\n",
    "    logV = np.log(cav_diagV)\n",
    "    \n",
    "    # cumul1 = mu_hat^2\n",
    "    cumul1 = (Cumul[:,0]**2).reshape(-1,1)\n",
    "    # cumul2 = log(sigma^2_hat)\n",
    "    cumul2 = (np.log(Cumul[:,1])).reshape(-1,1)    \n",
    "    \n",
    "    # logZ + 1/2 * ((mu_-i^2 / sigma_-i^2) + log(sigma_-i^2) - (mu_hat^2 / sigma_hat^2) + log(sigma_hat^2))\n",
    "    logZterms = logZ + np.multiply(np.divide(m2, cav_diagV) + logV - \n",
    "                                   (np.divide(cumul1, Cumul[:,1].reshape(-1,1)) + cumul2), 1/2)\n",
    "        \n",
    "    # c1 = mu_hat / sigma_hat^2 - mu_-i / sigma_-i^2 = v_tilde\n",
    "    #c1 = np.divide(Cumul[:,0].reshape(-1,1), Cumul[:,1].reshape(-1,1)) - (np.divide(cav_m, cav_diagV))\n",
    "    # c2 = 1 / sigma_hat^2 - 1 / sigma_-i^2 = tau_tilde\n",
    "    #c2 = np.divide(np.ones((datapoints,1)), Cumul[:,1].reshape(-1,1)) - (np.divide(np.ones((datapoints,1)), cav_diagV))\n",
    "    \n",
    "        \n",
    "    \n",
    "    ### hier sind die ganzen if-bedingungen, um negative werte und anderes zu pruefen\n",
    "    # kommt aber nie in die bedingungen rein, und hab trotzdem das problem mit negativen werten\n",
    "    c1 = np.zeros((datapoints,1))\n",
    "    c2 = np.zeros((datapoints,1))\n",
    "    for i in np.arange(datapoints):\n",
    "        if (1/cav_diagV[i] == 1/Cumul[i,1]):\n",
    "            c2[i] = 1e-4\n",
    "        else:\n",
    "            c2[i] = (1 / Cumul[i,1]) - (1 / cav_diagV[i])\n",
    "\n",
    "     \n",
    "    for k in np.arange(datapoints):\n",
    "        if((1/c2[k] == np.infty) and (1/cav_diagV[k] == 0 or gauss_m[k] == cav_m[k])):\n",
    "            c1[k] = cav_m[k] * cav_diagV[k]\n",
    "        else:\n",
    "            c1[k] = Cumul[k,0] / Cumul[k,1] - cav_m[k] / cav_diagV[k]\n",
    "\n",
    "    for j in np.arange(datapoints):\n",
    "        if (1/c2[j] + cav_diagV[j]) < 0:\n",
    "            c1[j] = Term[j,0]\n",
    "            c2[j] = Term[j,1]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "            \n",
    "    TermNew = np.concatenate((c1, c2), axis=1)\n",
    "    TermNew = np.multiply(Term, (1 - eps_damp)) + np.multiply(TermNew, eps_damp)\n",
    "\n",
    "    \n",
    "    return TermNew, logZterms, logZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute log of **probit function** \n",
    "\n",
    "**Rasmussen Appendix 3.9**    \n",
    "\n",
    "$\\Phi(f(x)) = \\frac{1}{2} (1 + erf( x / \\sqrt{2} )) $  \n",
    "\n",
    "\n",
    "**Here** multiplication with true observation values:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logprobitpow(X, p, q):\n",
    "    \"\"\"\n",
    "    Compute ncdflogbc for matrices -> log of standard normal cdf by 10th order Taylor expansion in the negative domain\n",
    "    log likelihood evaluations for various probit power likelihoods\n",
    "    \n",
    "    Args:\n",
    "        X: matrix (datapoints,96)\n",
    "        p: number of runs satisfying property for each parameter, repeated (datapoints,96)\n",
    "        q: number of runs not satisfying property, repeated (datapoints,96)\n",
    "        \n",
    "    Returns:\n",
    "        Za+Zb:\n",
    "    \"\"\"\n",
    "    \n",
    "    threshold = -np.sqrt(2)*5\n",
    "    Za = []\n",
    "    y = []\n",
    "    j = 0\n",
    "    for x in X:\n",
    "        y.append([])\n",
    "        #print(x)\n",
    "        for i in x:\n",
    "            if i >= 0:\n",
    "                y[j].append(np.log(1 + erf(i/np.sqrt(2))) - np.log(2))\n",
    "            elif ((threshold < i) and (i < 0)):\n",
    "                y[j].append(np.log(1 - erf((-i)/np.sqrt(2))) - np.log(2))\n",
    "            elif i <= threshold:\n",
    "                y[j].append(-1/2 * np.log(np.pi) - np.log(2) - 1/2 * (-i) * (-i) - \\\n",
    "                np.log((-i)) + np.log(1 - 1/(-i) + 3/((-i)**4) - 15/((-i)**6) + 105/((-i)**8) - 945/((-i)**10)))\n",
    "        j+=1\n",
    "    #print(y)\n",
    "    Za = np.multiply(y, numpy.matlib.repmat(p.reshape(-1,1), 1, 96))\n",
    "\n",
    "    Zb = []\n",
    "    y = []\n",
    "    j = 0\n",
    "    for x in (-X):\n",
    "        y.append([])\n",
    "        #print(x)\n",
    "        for i in x:\n",
    "            #print(i)\n",
    "            if i >= 0:\n",
    "                y[j].append(np.log(1 + erf(i/np.sqrt(2))) - np.log(2))\n",
    "            elif ((threshold < i) and (i < 0)):\n",
    "                y[j].append(np.log(1 - erf((-i)/np.sqrt(2))) - np.log(2))\n",
    "            elif i <= threshold:\n",
    "                y[j].append(-1/2 * np.log(np.pi) - np.log(2) - 1/2 * (-i) * (-i) - \\\n",
    "                np.log((-i)) + np.log(1 - 1/(-i) + 3/((-i)**4) - 15/((-i)**6) + 105/((-i)**8) - 945/((-i)**10)))\n",
    "        j+=1\n",
    "\n",
    "    Zb = np.multiply(y, numpy.matlib.repmat(q.reshape(-1,1), 1, 96))\n",
    "    return Za + Zb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Propagation Algorithm  \n",
    "\n",
    "<!--Problem: the exact computation of the posterior probability is not possible: use approximation from **Expectation Propagation (EP)** approach (high accuracy + computational efficiency) \n",
    "\n",
    "EP computes a Gaussian approximation to probabilistic models of the form\n",
    "$ p(x|y) = p_0(x) \\prod_i t_i (y_i,x_i)$   \n",
    "\n",
    "$p_0(x)$ is a multivariate Gaussian distribution coupling all $x_i$ variables (*site variables*), $t_i$ can be general univariate distributions. Those models are calles *latent Gaussian models*: p0 represents prior distribution, with ti representing non-Gaussian observation likelihoods.  \n",
    "EP approximation: likelihood terms replaced by univariate Gaussian terms $ q(x|y) = p_0(x) \\prod_i \\tilde{t}_i (y_i,x_i) $   \n",
    "-->\n",
    "\n",
    "\n",
    "Initialization: Create data set of 20 input values (uncertain parameter that is varied) and the respective output values (number of trajectories satisfying the property divided by total number of trajectories $\\rightarrow$ statistical estimate of satisfaction probablity)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data (number of runs satisfying property):  [[ 9.  8. 10.  8.  6.  7.  5.  6.  6.  6.  4.  2.  3.  3.  6.  2.  4.  3.\n",
      "   0.  3.]]\n"
     ]
    }
   ],
   "source": [
    "## configuration and data\n",
    "\n",
    "simulation_runs = scale = 5  # number of trajectories per input point\n",
    "paramValueSet = np.linspace(0.5, 5, 20).reshape(-1,1) # uncertain input parameter that is varied = population size\n",
    "datapoints = len(paramValueSet)  # number of input points\n",
    "paramValueOutputs = np.array([1,1,0.8,1,1,1,1,0.6,0.6,0.6,0.8,0,0.8,0.2,0.6,0,0.4,0.4,0,0.2]).reshape(-1,1) # statistical outputs of satisfaction \n",
    "data = trainingSet = [paramValueSet, paramValueOutputs] # set as training set for GP\n",
    "\n",
    "simulation_runs = scale = 10  # number of trajectories per input point\n",
    "paramValueSet = np.linspace(0, 50, 20).reshape(-1,1) # uncertain input parameter that is varied = population size\n",
    "datapoints = len(paramValueSet)  # number of input points\n",
    "paramValueOutputs = (np.array([9,8,10,8,6,7,5,6,6,6,4,2,3,3,6,2,4,3,0,3])/scale).reshape(-1,1) # statistical outputs of satisfaction \n",
    "data = trainingSet = [paramValueSet, paramValueOutputs] # set as training set for GP\n",
    "\n",
    "\n",
    "correction = 1e-4\n",
    "\n",
    "# define default hyperparameters for all kernels\n",
    "params = {'var': 1/scale,\n",
    "          'ell': 3,        \n",
    "          'var_b': 1,\n",
    "          'off': 1}\n",
    "\n",
    "# plot training data\n",
    "plt.scatter(paramValueSet, paramValueOutputs, marker='o', c='blue')\n",
    "plt.title(f'Training dataset with {simulation_runs} trajectories per input point')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('Satisfaction probability')\n",
    "plt.yticks([0, 1])\n",
    "plt.show()\n",
    "\n",
    "print(\"Actual data (number of runs satisfying property): \", (paramValueOutputs * scale).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### How do we choose parameters of local approximating distributions $t_i$?  \n",
    "\n",
    "\n",
    "**Algorithm** proceeds *iteratively*: update individual $t_i$ approximations sequentially until convergence (= all marginal distributions $q(f_i)$ are consistent with $\\hat{p}(f_i)$ ):  \n",
    "1. start from some current approximate posterior, from which we leave out a site index $i$ (remove approx. likelihood term corresponding to $i$, marginalise all other variables) $\\rightarrow$ marginal *cavity distribution*    \n",
    "2. Combine cavity distribution with exact likelihood $p(y_i|f_i)$ to get desired (non-Gaussian) marginal, or *tilted distribution*  \n",
    "3. Update EP approximation by replacing the initial approximation likelihood term with the new term $\\tilde{t}$ obtained by finding the Gaussian which matches the moments of the tilted distribution    \n",
    "4. Apply iteratively to all sites until the moment of the EP approximation does not change   \n",
    "\n",
    "\n",
    "(? Normally you iterate through all data points, but here you just take them all at once)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1\n",
      "Iteration  2\n",
      "Iteration  3\n",
      "Iteration  4\n",
      "Iteration  5\n",
      "Iteration  6\n",
      "Iteration  7\n",
      "Iteration  8\n",
      "Iteration  9\n",
      "Iteration  10\n",
      "Iteration  11\n",
      "Iteration  12\n",
      "Iteration  13\n",
      "Iteration  14\n",
      "Iteration  15\n",
      "Iteration  16\n",
      "Iteration  17\n",
      "Iteration  18\n",
      "Iteration  19\n",
      "Iteration  20\n",
      "Iteration  21\n",
      "Iteration  22\n",
      "Iteration  23\n",
      "Iteration  24\n",
      "\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "# initialization (all 0)\n",
    "# Prior\n",
    "gauss_C = kernel_rbf(paramValueSet, paramValueSet, params) + correction * np.eye(datapoints) # covariance training set\n",
    "\n",
    "gauss_LC_t = cholesky(gauss_C)  # cholesky decomposition, returns U from A=U'*U (U=L')\n",
    "gauss_LC = gauss_LC_t.T  # transpose LC' \n",
    "gauss_LC_diag = np.diagonal(gauss_LC).reshape(-1,1)\n",
    "\n",
    "logdet_LC = 2*np.sum(np.log(gauss_LC_diag))\n",
    "logZprior = 0.5*logdet_LC\n",
    "\n",
    "logZterms = np.zeros(datapoints).reshape(-1,1)\n",
    "logZloo = np.zeros(datapoints).reshape(-1,1)\n",
    "Term = np.zeros((datapoints, 2))  # Term = v_tilde, tau_tilde\n",
    "\n",
    "# compute marginal moments mu and sigma^2\n",
    "_, gauss_m, gauss_diagV = marginal_moments(Term, gauss_LC, gauss_LC_t)\n",
    "\n",
    "# related to likelihood approximation\n",
    "# true observation values (number of trajectories satisfying property)\n",
    "gauss_LikPar_p = paramValueOutputs * scale\n",
    "gauss_LikPar_q = scale - gauss_LikPar_p \n",
    "\n",
    "# gauss hermite: quadrature to approximate values of integral, returns abscissas (x) and weights (w) of\n",
    "# n-point Gauss-Hermite quadrature formula\n",
    "nodes = 96\n",
    "gauss_xGauss, gauss_wGauss = gausshermite(nodes)\n",
    "gauss_logwGauss = np.log(gauss_wGauss)\n",
    "\n",
    "# configurations for loop initialization\n",
    "MaxIter=1000\n",
    "tol=1e-6\n",
    "logZold=0\n",
    "logZ = 2*tol\n",
    "steps=0\n",
    "logZappx=0\n",
    "eps_damp=0.5\n",
    "\n",
    "while (np.abs(logZ-logZold)>tol) and (steps<MaxIter):\n",
    "    steps += 1\n",
    "    logZold = logZ\n",
    "    \n",
    "    # find cavity distribution parameters mu_-i and sigma^2_-i\n",
    "    cav_m, cav_diagV = cavities(gauss_diagV, gauss_m, Term)\n",
    "    \n",
    "    # update marginal moments mu_hat and sigma^2_hat, and site parameters v_tilde and tau_tilde\n",
    "    Term, logZterms, logZloo = ep_update(cav_diagV, cav_m, Term, eps_damp, gauss_LikPar_p,\n",
    "                      gauss_LikPar_q, gauss_xGauss, gauss_logwGauss)\n",
    "    \n",
    "    # recompute mu and sigma^2 from the updated parameters\n",
    "    logZappx, gauss_m, gauss_diagV = marginal_moments(Term, gauss_LC, gauss_LC_t)\n",
    "    \n",
    "    logZ = logZterms.sum() + logZappx\n",
    "    \n",
    "    print(\"Iteration \", steps)\n",
    "    \n",
    "print(\"\\nFinish\")\n",
    "    \n",
    "    \n",
    "logZ = logZ - logZprior\n",
    "gauss_logZloo = logZloo.sum()\n",
    "gauss_logZappx = logZappx\n",
    "gauss_logZterms = logZterms\n",
    "gauss_logZ = logZ\n",
    "gauss_Term = Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish Training  \n",
    "\n",
    "$\\tilde{\\mu} = \\tilde{v} * \\frac{1}{\\tilde{\\tau}} $  \n",
    "\n",
    "$\\tilde{\\Sigma}$ with diagonal $\\tilde{\\Sigma}_{ii} = \\tilde{\\sigma}^2$  \n",
    "\n",
    "$invC = (C + \\tilde{\\Sigma})^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tilde = gauss_Term[:,0].reshape(-1,1)\n",
    "tau_tilde = gauss_Term[:,1].reshape(-1,1)\n",
    "\n",
    "diagSigma_tilde = 1/tau_tilde\n",
    "\n",
    "mu_tilde = np.multiply(v_tilde, diagSigma_tilde)\n",
    "\n",
    "Sigma_tilde = np.zeros((datapoints, datapoints))\n",
    "np.fill_diagonal(Sigma_tilde, diagSigma_tilde)\n",
    "\n",
    "# inverse of K + Sigma_tilde\n",
    "invC = np.linalg.solve((gauss_C + Sigma_tilde), np.eye(len(mu_tilde)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get GP Posterior\n",
    "\n",
    "\n",
    "**Rasmussen 3.60, 3.61**  \n",
    "\n",
    "Predictive mean for latent variable $f_*$: $\\mathbb{E}_q[f_*|X,y,x_*] = k_*^T (K + \\tilde{\\Sigma})^{-1} \\tilde{\\mu}$   \n",
    "\n",
    "Predictive variance: $\\mathbb{V}_q[f_*|X,y,x_*] = k(x_*,x_*) - k_*^T (K + \\tilde{\\Sigma})^{-1} k_*$  \n",
    "\n",
    "\n",
    "**Here:**  \n",
    "\n",
    "$fs = (ks (C + \\tilde{\\Sigma})^{-1}) \\tilde{\\mu}$  \n",
    "\n",
    "$vfs = kss - (ks (C + \\tilde{\\Sigma})^{-1} ) * ks^T$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test set for which posterior is derived\n",
    "#testpoints = X_s = np.linspace(0, 20, 100).reshape(-1,1)\n",
    "testpoints = X_s = np.linspace(0, 55, 100).reshape(-1,1)\n",
    "\n",
    "\n",
    "# calculate variances of testset and covariances of test & training set (apply kernel)\n",
    "kss = kernel_rbf(testpoints, testpoints, params) #+ correction * np.eye(testpoints) \n",
    "ks = kernel_rbf(testpoints, paramValueSet, params) #+ correction * np.eye(datapoints)\n",
    "\n",
    "\n",
    "# predictive mean \n",
    "fs = np.matmul(np.matmul(ks, invC), mu_tilde)\n",
    "#fs = ks.T.dot(np.linalg.solve(invC.T, np.linalg.solve(invC, mu_tilde)))\n",
    "\n",
    "# predictive variance -> here only diagonal\n",
    "vfs = (np.diagonal(kss) - (np.diagonal(np.matmul(np.matmul(ks, invC), ks.T)))).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probit Regression Posterior\n",
    "Compute confidence bounds and plot results  \n",
    "\n",
    "\n",
    "**Rasmussen 3.63**   \n",
    "\n",
    "Predictive probability $q(y_*=1|X,y,x_*) = \\phi(\\frac{\\mathbb{E}_q[f_*|X,y,x_*]}{\\sqrt{1 + \\mathbb{V}_q[f_*|X,y,x_*]}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to compute probit values\n",
    "def standardNormalCDF(x):\n",
    "    return 1/2 + 1/2 * erf(x * (1/np.sqrt(2)))\n",
    "\n",
    "\n",
    "cached_denominator = (1 / np.sqrt(1 + vfs)).reshape(-1,1)\n",
    "\n",
    "\n",
    "# get probabilities with probit function\n",
    "probabilities = standardNormalCDF(fs * cached_denominator)\n",
    "\n",
    "\n",
    "# compute confidence bounds\n",
    "lowerbound = standardNormalCDF((fs - 1.96 * np.sqrt(vfs).reshape(-1,1)) *\n",
    "                              cached_denominator)\n",
    "upperbound = standardNormalCDF((fs + 1.96 * np.sqrt(vfs).reshape(-1,1)) *\n",
    "                              cached_denominator)\n",
    "\n",
    "# plot data\n",
    "plt.plot(testpoints, probabilities, lw=1.5, ls='-')\n",
    "plt.fill_between(testpoints.ravel(), lowerbound.ravel(), upperbound.ravel(), alpha=0.2)\n",
    "plt.scatter(paramValueSet, paramValueOutputs, marker='o', c='blue')\n",
    "plt.title(f'Classification with {scale} observations per input point')\n",
    "plt.xlabel('Population size $N$')\n",
    "plt.ylabel('Satisfaction probability')\n",
    "#plt.yticks([0, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
