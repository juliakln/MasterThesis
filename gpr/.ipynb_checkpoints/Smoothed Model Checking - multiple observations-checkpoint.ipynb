{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: estimate satisfaction function of a formula from instances of its satisfaction on individual runs at discrete parameter values\n",
    "\n",
    "We use Gaussian Process Classification to estimate the satisfaction function.\n",
    "Problem: the exact computation of the posterior probability is not possible --> use approximation from **Expectation Propagation (EP)** approach (high accuracy + computational efficiency) \n",
    "\n",
    "EP computes a Gaussian approximation to probabilistic models of the form\n",
    "$ p(x|y) = p_0(x) \\prod_i t_i (y_i,x_i)$   \n",
    "\n",
    "$p_0(x)$ is a multivariate Gaussian distribution coupling all $x_i$ variables (*site variables*), $t_i$ can be general univariate distributions. Those models are calles *latent Gaussian models*: p0 represents prior distribution, with ti representing non-Gaussian observation likelihoods.  \n",
    "EP approximation: likelihood terms replaced by univariate Gaussian terms $ q(x|y) = p_0(x) \\prod_i \\tilde{t}_i (y_i,x_i) $  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "\n",
    "import math\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.special import erf \n",
    "# scipy gives upper triangular matrix, numpy lower!\n",
    "from scipy.linalg import cholesky\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel\n",
    "\n",
    "We place a GP prior over the latent function $f(x)$ and then squash it to obtain the prior on $\\pi(x) = p(y=1|x) = \\phi(f(x))$.  \n",
    "We use the squared exponential covariance function $k(x,x')= \\sigma^2 exp(- \\frac{(x-x')^2}{2\\lambda^2}) $.  \n",
    "Squash it with: *probit* transformation (cdf of normal distribution, $\\Phi(z) = \\int^z_{-\\inf} \\mathcal{N}(x|0,1)dx$).\n",
    "\n",
    "We don't observe values of f itself, only inputs X and class labels y. We are only interested in $\\pi$.  \n",
    "\n",
    "We set a zero-mean Gaussian prior for f: $p(f|X) = \\mathcal{N}(f|0,K)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_rbf(x, y, param):\n",
    "    \"\"\" Radial Basis Function Kernel \n",
    "    \n",
    "    Args:\n",
    "        x: First input vector of kernel (N,1)\n",
    "        y: Second input vector of kernel (N,1)\n",
    "        param: Hyperparameter of kernel: scale factor variance and lengthscale ell\n",
    "        \n",
    "    Returns:\n",
    "        Covariance matrix of each pairwise combination of set of points\n",
    "    \"\"\"\n",
    "    variance = param['var']\n",
    "    lengthscale = param['ell']\n",
    "    # Euclidean distance between points\n",
    "    eucdist = np.sum(x**2,1).reshape(-1,1) + np.sum(y**2,1) - 2*np.dot(x, y.T)\n",
    "    return variance * np.exp(-0.5 * eucdist * 1/(lengthscale**2))\n",
    "\n",
    "\n",
    "def kernel_linear(x, y, param):\n",
    "    \"\"\" Linear Kernel\n",
    "    \n",
    "    Args:\n",
    "        x: First input vector of kernel (N,1)\n",
    "        y: Second input vector of kernel (N,1)\n",
    "        param: Hyperparameter of kernel: scale factor variance, variance_b and offset off\n",
    "        \n",
    "    Returns: \n",
    "        Covariance matrix of each pairwise combination of set of points\n",
    "    \"\"\"\n",
    "    variance = param['var']\n",
    "    variance_b = param['var_b']\n",
    "    offset = param['off']\n",
    "    return variance_b + variance * np.dot((x-offset), (y-offset).T)\n",
    "\n",
    "\n",
    "\n",
    "# define default hyperparameters for all kernels\n",
    "params = {'var': 1,\n",
    "          'ell': 1,        \n",
    "          'var_b': 1,\n",
    "          'off': 1}\n",
    "\n",
    "\n",
    "# TODO: optimize hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "2 steps:  \n",
    "- compute distribution of latent variable corresponding to a test case: $p(f_*|X,y,x_*) = \\int p(f_*|X,x_*,f) p(f|X,y) df$, where $p(f|X,y) = p(y|f)p(f|X)/p(y|X)$ is the posterior over the latent variables      \n",
    "\n",
    "   \n",
    "     \n",
    "- use this distribution over latent $f_*$ to produce probabilistic prediction: $\\overline{x}_* = p(y_*=1|X,y,x_*) = \\int \\sigma(f_*)p(f_*|X,y,x_*)df$   \n",
    "\n",
    "\n",
    "Non-Gaussian likelihood makes integral intractable $\\rightarrow$ approximate with Gaussian posterior $\\Rightarrow$ Expectation Propagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Propagation\n",
    "\n",
    "Posterior given by Bayes rule as product of normalization term, prior and likelihood: $p(f|X,y) = \\frac{1}{Z} p(f|X) \\prod p(y_i|f_i)$  \n",
    "Prior $p(f|X)$ is Gaussian  \n",
    "Likelihood factorizes over training cases  \n",
    "Normalization term = marginal likelihood: $Z = p(y|X) = \\int p(f|X) \\prod p(y_i|f_i) df$  \n",
    "\n",
    "Probit likelihood for binary classification: $p(y_i|f_i) = \\Phi(f_iy_i)$  \n",
    "$\\rightarrow$ approximate by local likelihood approximation (unnormalized Gaussian function in latent variable $f_i$): $p(y_i|f_i) \\approx t_i ( f_i|\\tilde{Z}_i,\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2) = \\tilde{Z}_i \\mathcal{N}(f_i|\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2)$  \n",
    "\n",
    "Product of independent local likelihoods $t_i$: $\\prod t_i(f_i| \\tilde{Z}_i,\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2) = \\mathcal{N}(\\tilde{\\mu},\\tilde{\\Sigma}) \\prod \\tilde{Z}_i$, where $\\tilde{\\mu}$ is vector of $\\tilde{\\mu}_i$ and $\\tilde{\\Sigma}$ is diagonal with $\\tilde{\\Sigma}_{ii} = \\tilde{\\sigma}^2_i$.  \n",
    "\n",
    "Approximate posterior $p(f|X,y)$ by: $q(f|X,y) = \\frac{1}{Z_{EP}} p(f|X) \\prod t_i(f_i| \\tilde{Z}_i,\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2) = \\mathcal{N}(\\mu,\\Sigma)$ [3.53] with $Z_{EP}=q(y|X)$ (approximation to normalizing term Z from previous eq.), $\\mu=\\Sigma\\tilde{\\Sigma}^{-1}\\tilde{\\mu}$ and $\\Sigma=(K^{-1}+\\tilde{\\Sigma}^{-1})^{-1}$  \n",
    "\n",
    "### How do we choose parameters of local approximating distributions $t_i$?  \n",
    "Update individual $t_i$ approximations sequentially. Iterate these 4 steps until convergence:  \n",
    "1. start from some current approximate posterior, from which we leave out current $t_i$ $\\rightarrow$ marginal cavity distribution  \n",
    "2. Combine cavity distribution with exact likelihood $p(y_i|f_i)$ to get desired (non-Gaussian) marginal  \n",
    "3. Choose Gaussian approximation to marginal  \n",
    "4. Compute the $t_i$ which makes posterior have the desired marginal from step 3   \n",
    "\n",
    "Approximate posterior for $f_i$ contains 3 kinds of terms:  \n",
    "1. Prior $p(f|X)$  \n",
    "2. Local approximate likelihoods $t_j$ for all cases $j\\neq i$  \n",
    "3. Exact likelihood for case i, $p(y_i|f_i) = \\Phi(y_if_i)$   \n",
    "\n",
    "Goal: combine these sources of information and choose parameters of $t_i$ such that the marginal posterior is as accurate as possible. \n",
    "\n",
    "1. Combine prior and local likelihood approximations into cavity distribution: $q_{-i}(f_i) \\propto \\int p(f|X) \\prod_{j\\neq i} t_j (f_j|\\tilde{Z}_j, \\tilde{\\mu}_j, \\tilde{\\sigma}_j^2) df_j$  \n",
    "Either by explicitly multiplying out the terms, or by removing approximate likelihood i from the approximate posterior in 3.53.\n",
    "2. Combine this with exact likelihood for case i. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Initialization, perform statistical model checking\n",
    "\n",
    "- Set parameters for smoothed model checking  \n",
    "- Invent parameters: assume 10 trajectories per input point and statistically estimate outputs (number of runs satisfying property / total number of runs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Perform smoothed model checking (SMC 65)\n",
    "\n",
    "getAnalyticApproximation(data, parameters, options)  \n",
    "-> optimize hyperparameters for rbf kernel or take default ones  \n",
    "-> doTraining = probit gp regression  \n",
    "   -> expectationPropagation\n",
    "   \n",
    "then return performSmoothedModelChecking(approx, parameters, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for EP  \n",
    "\n",
    "Marginal moments  \n",
    "\n",
    "\n",
    "\n",
    "**Rasmussen 3.53:**. \n",
    "\n",
    "$q(f|X,y) \\overset{\\Delta}{=} \\frac{1}{Z_{EP}} p(f|X) \\prod t_i(f_i| \\tilde{Z}_i,\\tilde{\\mu}_i,\\tilde{\\sigma}_i^2) = \\mathcal{N}(\\mu,\\Sigma)$   \n",
    "\n",
    "with $Z_{EP}=q(y|X)$,   \n",
    "\n",
    "$\\mu=\\Sigma\\tilde{\\Sigma}^{-1}\\tilde{\\mu}$, $\\tilde{\\Sigma}$ is diagonal with $\\tilde{\\Sigma}_{ii} = \\tilde{\\sigma}_i^2$   \n",
    "\n",
    "$\\Sigma=(K^{-1}+\\tilde{\\Sigma}^{-1})^{-1}$   \n",
    "\n",
    "\n",
    "\n",
    "**Here:**  \n",
    "\n",
    "\n",
    "! Attention: computation of cholesky(A) may fail when A is not PD (for large amplitudes) --> add another +I for computational stability?    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(Note: Cholesky returns $L$ for $A = L' * L $)    \n",
    "\n",
    "$L = (cholesky({LC}' * (\\tilde{\\tau} * {LC}) + I))'$  \n",
    "\n",
    "$L * W = LC' \\rightarrow$ Solve for $W$  \n",
    "\n",
    "$diagV = diag(W' * W)$  \n",
    "\n",
    "$m = W' * (W * \\tilde{v})$  \n",
    "\n",
    "$logdet = -2 * \\sum \\log(diag(L)) + 2 * \\sum \\log(diag(LC))$  \n",
    "\n",
    "$logZappx = \\frac{1}{2} (m' * \\tilde{v} + logdet)$\n",
    "\n",
    "\n",
    "\n",
    "Note:   \n",
    "$\\tilde{v} = \\tilde{\\mu} \\tilde{\\sigma}^{-2} = \\tilde{\\mu} * \\tilde{\\tau} $  \n",
    "$\\tilde{\\tau} = \\tilde{\\sigma}^{-2}$  \n",
    "\n",
    "\n",
    "\n",
    "Irgendwie ergibts keinen Sinn, dass ich immer mit gauss_LC rechne, da ich das nur 1x ganz am Anfang ausrechne. Wäre es nicht sinnvoller die neu berechneten Sigmas oder diagVs oder was auch immer zu updaten? Bzw gauss_m und gauss_diagV? In Rasmussen rechnet man ja auch Sigma = Sigma - ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_moments(Term, gauss_LC, gauss_LC_t):\n",
    "    \"\"\"\n",
    "    Computes marginal moments\n",
    "    \n",
    "    Args:\n",
    "        Term: v_tilde, tau_tilde (datapoints, 2)\n",
    "        gauss_LC:\n",
    "        gauss_LC_t: \n",
    "        \n",
    "    Returns:\n",
    "        logZappx: \n",
    "        gauss_m: mu (datapoints,1)\n",
    "        gauss_diagV: diagonal of sigma^2 (datapoints,1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # A = LC' * (tau_tilde * gauss_LC) + I \n",
    "    tmp = np.multiply(Term[:,1], gauss_LC)\n",
    "    A = np.matmul(gauss_LC_t, tmp) + 2 * np.eye(datapoints)\n",
    "    gauss_L = cholesky(A).T  \n",
    "\n",
    "    # W = L\\LC' -> Solve L*W = LC'\n",
    "    gauss_W = np.linalg.solve(gauss_L, gauss_LC_t)\n",
    "    gauss_diagV = np.diagonal(np.matmul(gauss_W.T, gauss_W)).reshape(-1,1)\n",
    "    \n",
    "    # m = W'*(W * v_tilde)\n",
    "    tmp = np.matmul(gauss_W, Term[:,0])\n",
    "    gauss_m = np.matmul(gauss_W.T, tmp).reshape(-1,1)\n",
    "\n",
    "    # logdet = -2*sum(log(diag(L))) + 2*sum(log(diag(LC)))\n",
    "    logdet = -2*np.sum(np.log(np.diagonal(gauss_L))) # + 2*np.sum(np.log(np.diag(gauss_LC))) (das ist schon logdet_LC)\n",
    "    logdet += logdet_LC\n",
    "\n",
    "    # logZappx = 1/2(m' * v_tilde + logdet)\n",
    "    logZappx = 0.5 * (np.dot(gauss_m.T, Term[:,0]) + logdet)\n",
    "\n",
    "    return logZappx, gauss_m, gauss_diagV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Gauss–Hermite_quadrature  \n",
    "\n",
    "**Gauss-Hermite quadrature** is a form of Gaussian quadrature for approximating the value of integrals of the following kind:  \n",
    "\n",
    "$ \\int_{-\\infty}^{+\\infty} e^{-x^2} f(x) dx \\approx \\sum_{i=1}^n w_i f(x_i)  $  \n",
    "\n",
    "where $n$ is the number of sample points used (here: nodes). The $x_i$ are the roots of the physicists' version of the Hermite polynomial $H_n(x)$ and the associated weights $w_i$ are given by:  \n",
    "\n",
    "$ w_i = \\frac{ 2^{n-1} n! \\sqrt{\\pi}}{n^2 [H_{n-1}(x_i)]^2}$   \n",
    "\n",
    "\n",
    "Binary classification: determining moments of tilted distribution requires solving only 1-dimensional integrals; assuming probit likelihood functions $\\rightarrow$ univariate integrals can be computed efficiently without quadrature. But here: need quadrature because we have multiple observations per input point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gausshermite(nodes):\n",
    "    \"\"\"\n",
    "    Gauss-Hermite \n",
    "    https://indico.frib.msu.edu/event/15/attachments/40/157/Gaussian_Quadrature_Numerical_Recipes.pdf\n",
    "    \n",
    "    Approximate integral of a formula by the sum of its functional values at some points\n",
    "    \n",
    "    Args:\n",
    "        nodes: number of Gauss-Hermite nodes (96,1)\n",
    "        \n",
    "    Returns:\n",
    "        x0: abscissas (96,1)\n",
    "        w0: weights (96,1)\n",
    "    \"\"\"\n",
    "\n",
    "    x0 = np.zeros((nodes, 1))\n",
    "    w0 = np.zeros((nodes, 1))\n",
    "    m = int((nodes+1)/2)\n",
    "    z,pp,p1,p2,p3 = 0,0,0,0,0\n",
    "    \n",
    "    for i in range(m):\n",
    "        if i==0:\n",
    "            z = np.sqrt(2*nodes+1) - 1.85575 * ((2*nodes+1)**(-0.166667))\n",
    "        elif i==1:\n",
    "            z = z - 1.14 * (nodes**0.426) / z\n",
    "        elif i==2:\n",
    "            z = 1.86 * z - 0.86 * x0[0]\n",
    "        elif i==3:\n",
    "            z = 1.91 * z - 0.91 * x0[1]\n",
    "        else:\n",
    "            z = 2.0 * z - x0[i - 2]\n",
    "\n",
    "        for its in range(10):\n",
    "            p1 = 1/np.sqrt(np.sqrt(np.pi))\n",
    "            p2 = 0\n",
    "            for j in range(1,nodes+1):\n",
    "                p3=p2\n",
    "                p2=p1\n",
    "                a = z*np.sqrt(2/j)*p2\n",
    "                b = np.sqrt((j-1)/j)*p3\n",
    "                p1=a-b\n",
    "            pp=np.sqrt(2*nodes)*p2\n",
    "            z1=z\n",
    "            z=z1-p1/pp\n",
    "            if np.abs(z-z1)<2.2204e-16:\n",
    "                break\n",
    "\n",
    "        x0[i] = z\n",
    "        x0[nodes-1-i] = -z\n",
    "        w0[i] = 2/(pp*pp)\n",
    "        w0[nodes-1-i] = w0[i]\n",
    "\n",
    "    w0 = np.divide(w0, np.sqrt(np.pi))\n",
    "    x0 = np.multiply(x0, np.sqrt(2))\n",
    "    x0 = np.sort(x0, axis=None).reshape(-1,1)\n",
    "    \n",
    "    return x0, w0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute new posterior marginal moments $\\hat{\\mu}$ and $\\hat{\\sigma}^2$   \n",
    "\n",
    "Find new Gaussian marginal which best approximates the product of the cavity distribution and the exact likelihood $\\hat{q}(f_i) \\overset{\\Delta}{=} \\hat{Z}_i ~ \\mathcal{N}(\\hat{\\mu}_i, \\hat{\\sigma}^2_i) \\simeq q_{-i} (f_i) p (y_i | f_i) $.  \n",
    "\n",
    "It is well known that distribution $q(x)$ which minimizes KL$(p(x)||q(x))$ is the one whose first and second moments match that of $p(x)$. $\\hat{q}(f_i)$ is unnormalized, so choose additionally the condition that zero-th moments (normalizing constants) should match when choosing the parameters of $\\hat{q}(f_i)$ to match the right-hand side of above equation.  \n",
    "Derivation of moments is complicated (see Appendix 3.9). Desired posterior marginal moments are:  \n",
    "\n",
    "**Rasmussen 3.58:**  \n",
    "\n",
    "$ \\hat{Z} = \\Phi (z)$  \n",
    "\n",
    "$ \\hat{\\mu} = \\mu_{-i} + \\frac{y ~ \\sigma^2_{-i} \\mathcal{N}(z)} { \\Phi(z) \\sqrt{1 + \\sigma^2_{-i}}} $  \n",
    "\n",
    "$ \\hat{\\sigma}^2 = \\sigma^2_{-i} - \\frac{ \\sigma^4_{-i} \\mathcal{N}(z)} {(1 + \\sigma^2_{-i}) \\Phi (z) } (z + \\frac{\\mathcal{N}(z)} {\\Phi (z)} ) $,  \n",
    "\n",
    "\n",
    "where $z = \\frac{y ~ \\mu_{-i}} { \\sqrt{1 + \\sigma^2_{-i}} } $  \n",
    "\n",
    "\n",
    "Here:  \n",
    "\n",
    "$G = \\text{logprobitpow}((\\sigma_{-i} * xGH + \\mu_{-i}), p, q) + logwGH'$, $G = G - \\max(G)$ for each datapoint   \n",
    "\n",
    "**Gauss-Hermite** to match distribution https://www.wouterdenhaan.com/numerical/integrationslides.pdf \n",
    "Get $n$ nodes ($xGH$) and weights ($logwGH$) from function *gausshermite*. Expectation of normally distributed variable: $E[h(y)]$ with $y \\sim \\mathcal{N}(\\mu,\\sigma^2)$.  \n",
    "Calculate $\\int_{-\\infty}^{\\infty} \\frac{1}{\\sigma \\sqrt{2 \\pi}} h(y) \\exp(- \\frac{(y-\\mu)^2}{2\\sigma^2})dy$  \n",
    "$\\rightarrow$ do a trick with change of variables and transformation, then approximation is:  \n",
    "\n",
    "$E[h(y)] \\approx \\sum_{i=1}^n \\frac{1}{\\sqrt{\\pi}} w_i h(\\sqrt{2} \\sigma x_i + \\mu)$\n",
    "\n",
    "$\\rightarrow$ this relates to $\\sum \\text{logprobitpow}((\\sigma_{-i} * xGH + \\mu_{-i}), p, q) + logwGH'$, because nodes $x_i$ are already multiplied by $\\sqrt{2}$ and weights $w_i$ are already divided by $\\sqrt{\\pi}$ in *gausshermite*. Since we're taking the logarithm, we have $\\log x \\cdot y = \\log x + \\log y$, so $+ logwGH$ in $G$ instead of $\\cdot w_i$.   \n",
    "\n",
    "But: Why do we take maximum then instead of summing the values?  \n",
    "\n",
    "\n",
    "$logZ = maxG + \\log(\\sum e^G)$ (sum over rows, for each datapoint)  \n",
    "\n",
    "Moments:  \n",
    "\n",
    "$\\hat{\\mu} = \\mu_{-i} + \\Delta_m \\rightarrow \\Delta_m = \\frac{\\sigma_{-i} * (e^G * xGH)}{\\sum e^G} $  \n",
    "\n",
    "$\\hat{\\sigma}^2 = \\frac{\\sigma_{-i}^2 * (e^G * xGH^2)}{\\sum e^G} - \\Delta_m^2$  \n",
    "\n",
    "$logZ = \\max(G) + \\log(\\sum \\exp(G - \\max(G))) = \\log \\sum \\exp(G)$ is smooth approximation to get largest element of $G$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussHermiteNQ(FuncPar_p, FuncPar_q, cav_m, cav_v, xGH, logwGH):\n",
    "    \"\"\"\n",
    "    Gauss-Hermite numerical quadrature for moment computation\n",
    "    \n",
    "    Args:\n",
    "        FuncPar_p: number of runs satisfying property for each parameter value (input) (datapoints,1)\n",
    "        FuncPar_q: number of runs not satisfying property (datapoints,1)\n",
    "        cav_m: cavity mean mu_-i\n",
    "        cav_v: cavity variance sigma^2_-i\n",
    "        xGH: abscissas (Gauss-Hermite)\n",
    "        logwGH: weights (Gauss-Hermite)\n",
    "        \n",
    "    Returns:\n",
    "        logZ: largest element of expectation of normally distributed variable?\n",
    "        Cumul: mu_hat, sigma^2_hat (datapoints,2)\n",
    "    \"\"\"\n",
    "    \n",
    "    Nnodes = len(xGH)\n",
    "    \n",
    "    # sigma_-i\n",
    "    stdv = np.sqrt(cav_v).reshape(-1,1)\n",
    "\n",
    "    # HIER PROBLEM: Dadurch dass stdv von cavity gerechnet wird & cavity variance auch negativ sein kann,\n",
    "    # ist stdv nicht für alle Werte definiert -> dadurch cholesky in marginal_moments = 2I\n",
    "    Y = np.matmul(stdv, xGH.reshape(1,-1)) + numpy.matlib.repmat(cav_m, 1, Nnodes)\n",
    "        \n",
    "    G = np.array(logprobitpow(Y, FuncPar_p, FuncPar_q) + numpy.matlib.repmat(logwGH.T, datapoints, 1))\n",
    "        \n",
    "    # maximum of each row (input value) over all 96 nodes\n",
    "    maxG = G.max(axis=1).reshape(-1,1)\n",
    "    # subtract maximum value\n",
    "    G = G - np.matlib.repmat(maxG, 1, 96)\n",
    "    # exponential value\n",
    "    expG = np.exp(G)\n",
    "    # denominator (row sum)\n",
    "    denominator = expG.sum(axis=1).reshape(-1,1)\n",
    "    logdenominator = np.log(denominator)\n",
    "    logZ = maxG + logdenominator\n",
    "    \n",
    "    Cumul = np.zeros((len(FuncPar_p), 2))\n",
    "\n",
    "\n",
    "    # deltam = stdv * (expG * xGH) / denominator\n",
    "    deltam = np.divide(np.multiply(stdv, np.matmul(expG, xGH)), denominator)\n",
    "\n",
    "    # mu_hat = mu_-i + deltam    \n",
    "    Cumul[:,0] = (cav_m + deltam).reshape(-1)\n",
    "    \n",
    "    xGH2 = xGH**2\n",
    "    deltam2 = deltam**2\n",
    "\n",
    "    # sigma^2_hat\n",
    "    Cumul[:,1] = (np.divide(np.multiply(cav_v, np.matmul(expG, xGH2)), denominator) - deltam2).reshape(-1)\n",
    "        \n",
    "    return logZ, Cumul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cavity parameters $\\mu_{-i}$ and $\\sigma^2_{-i}$   \n",
    "\n",
    "**Rasmussen 3.56:**   \n",
    "\n",
    "\n",
    "$cav_m = \\mu_{-i} = \\sigma_{-i}^2 \\cdot ( \\frac{\\mu}{\\sigma^2} - \\frac{\\tilde{\\mu}}{\\tilde{\\sigma}^2} )$   \n",
    "\n",
    "\n",
    "\n",
    "$cav_v =  \\sigma_{-i}^2 = \\frac{1}{\\sigma^{-2} - \\tilde{\\sigma}^{-2}}  $   \n",
    "\n",
    "\n",
    "**Here:** $diagV = \\sigma^2$ and $\\tilde{\\tau} = \\tilde{\\sigma}^{-2}$ and $\\tilde{v} = \\tilde{\\mu} \\tilde{\\sigma}^{-2}$; transforming the equations shows that they're equal:      \n",
    "\n",
    "$cav_m = \\frac{m + (- \\tilde{v} \\cdot diagV) }{1 + (- \\tilde{\\tau} \\cdot diagV)} = \\frac{ \\mu - \\tilde{\\sigma}^{-2} \\tilde{\\mu} \\sigma^2}{1 - \\tilde{\\sigma}^{-2} \\sigma^2} $   \n",
    "\n",
    "\n",
    "$cav_{diagV} = \\frac{diagV}{1 + (- \\tilde{\\tau} * diagV)} = \\frac{1}{diagV^{-1} - \\tilde{\\tau}} = \\frac{1}{\\sigma^{-2} - \\tilde{\\sigma}^{-2}}$   \n",
    "\n",
    "\n",
    "The cavity distribution combines the prior and the local likelihood approximations; afterwards, it is combined with the exact likelihood for case $i$. To do so, we remove the approximate likelihood $i$ from the approximate posterior by dividing the marginal with the approximate term $t_i$.  \n",
    "$q_{-i}(x) = \\frac{q(x)}{\\tilde{\\tau}_i(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cavities(gauss_diagV, gauss_m, Term):\n",
    "    \"\"\"\n",
    "    Compute cavity distribution by removing the effect of a single factor from q\n",
    "    \n",
    "    Args:\n",
    "        gauss_diagV: sigma^2\n",
    "        gauss_m: mu\n",
    "        Term: v_tilde, tau_tilde (datapoints,2)\n",
    "        \n",
    "    Returns:\n",
    "        cav_m: cavity mean mu_-i\n",
    "        cav_diagV: cavity variance sigma^2_-i\n",
    "    \"\"\"\n",
    "    \n",
    "    # s = 1 / (1 + -tau_tilde * diagV)\n",
    "    s = np.divide(1, (1 + np.multiply(-Term[:,1].reshape(-1,1), gauss_diagV)))\n",
    "\n",
    "    # cav_diagV = s * diagV\n",
    "    cav_diagV = np.multiply(s, gauss_diagV)\n",
    "    \n",
    "    # cav_m = s * (m + (-v_tilde * diagV))\n",
    "    cav_m = np.multiply(s, (gauss_m + np.multiply(-Term[:,0].reshape(-1,1), gauss_diagV)))\n",
    "    \n",
    "    return cav_m, cav_diagV\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update site parameters $\\tilde{v}$ and $\\tilde{\\tau}$ with new posterior marginal moments $\\hat{\\mu}$ and $\\hat{\\sigma}^2$.  \n",
    "\n",
    "Final step is to compute the parameters of the approximation $t_i$ which achieves a match with the desired moments. In particular, the product of the cavity distribution and the local approximation must have the desired moments.  \n",
    "\n",
    "\n",
    "**Rasmussen 3.59**   \n",
    "\n",
    "$\\tilde{\\mu}_i = \\tilde{\\sigma}_i^2 ( \\hat{\\sigma}_i^{-2} \\hat{\\mu}_i - \\sigma_{-i}^{-2} \\mu_{-i})$  \n",
    "\n",
    "$\\tilde{\\sigma}_i^2 = (\\hat{\\sigma}_i^{-2} - \\sigma_{-i}^{-2})^{-1}$  \n",
    "\n",
    "\n",
    "**Here**: just simple transformation  \n",
    "\n",
    "\n",
    "$\\tilde{v} = \\hat{\\sigma}_i^{-2} \\hat{\\mu}_i - \\sigma_{-i}^{-2} \\mu_{-i} = \\tilde{\\sigma}_i^{-2} \\tilde{\\mu}_i$  \n",
    "\n",
    "$\\tilde{\\tau} = 1 / \\hat{\\sigma}_i^2 - 1 / \\sigma_{-i}^2 = \\tilde{\\sigma}_i^{-2}$   \n",
    "\n",
    "$logZterms = logZ + \\frac{1}{2} * (\\frac{\\mu_{-i}^2}{\\sigma_{-i}^2} + \\log(\\sigma_{-i}^2) - \\frac{\\hat{\\mu}^2}{\\hat{\\sigma}^2} + \\log(\\hat{\\sigma}^2))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ep_update(cav_diagV, cav_m, Term, eps_damp, gauss_LikPar_p,\n",
    "              gauss_LikPar_q, gauss_xGauss, gauss_logwGauss):\n",
    "    \"\"\"\n",
    "    Update site parameters\n",
    "    \n",
    "    Args:\n",
    "        cav_diagV: cavity variance sigma^2_-i\n",
    "        cav_m: cavity mean mu_-i\n",
    "        Term: v_tilde, tau_tilde (datapoints,2)\n",
    "        eps_damp: 0.5\n",
    "        gauss_LikPar_p: number of runs satisfying property for each parameter (datapoints,1)\n",
    "        gauss_LikPar_q: number of runs not satisfying property (datapoints,1)\n",
    "        gauss_xGauss: abscissas of Gauss-Hermite\n",
    "        gauss_logwGauss: weights of Gauss-Hermite\n",
    "        \n",
    "    Returns:\n",
    "        TermNew: updated v_tilde, tau_tilde (datapoints,2)\n",
    "        logZterms:\n",
    "        logZ:\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Cumul = [mu_hat, sigma^2_hat]    \n",
    "    # Evaluate new approximation q_hat(x) by setting the sufficient statistics equal to that of probit*cavity\n",
    "    logZ, Cumul = GaussHermiteNQ(gauss_LikPar_p, gauss_LikPar_q, cav_m, cav_diagV, gauss_xGauss, gauss_logwGauss)\n",
    "    \n",
    "    \n",
    "    # m2 = mu_-i ^2\n",
    "    m2 = cav_m**2\n",
    "    # loV = log(sigma_-i^2)\n",
    "    logV = np.log(cav_diagV)\n",
    "    \n",
    "    # cumul1 = mu_hat^2\n",
    "    cumul1 = (Cumul[:,0]**2).reshape(-1,1)\n",
    "    # cumul2 = log(sigma^2_hat)\n",
    "    cumul2 = (np.log(Cumul[:,1])).reshape(-1,1)    \n",
    "    \n",
    "    # logZ + 1/2 * ((mu_-i^2 / sigma_-i^2) + log(sigma_-i^2) - (mu_hat^2 / sigma_hat^2) + log(sigma_hat^2))\n",
    "    logZterms = logZ + np.multiply(np.divide(m2, cav_diagV) + logV - \n",
    "                                   (np.divide(cumul1, Cumul[:,1].reshape(-1,1)) + cumul2), 1/2)\n",
    "        \n",
    "    # c1 = mu_hat / sigma_hat^2 - mu_-i / sigma_-i^2 = v_tilde\n",
    "    #c1 = np.divide(Cumul[:,0].reshape(-1,1), Cumul[:,1].reshape(-1,1)) - (np.divide(cav_m, cav_diagV))\n",
    "    # c2 = 1 / sigma_hat^2 - 1 / sigma_-i^2 = tau_tilde\n",
    "    #c2 = np.divide(np.ones((datapoints,1)), Cumul[:,1].reshape(-1,1)) - (np.divide(np.ones((datapoints,1)), cav_diagV))\n",
    "    \n",
    "        \n",
    "    \n",
    "    ### hier sind die ganzen if-bedingungen, um negative werte und anderes zu pruefen\n",
    "    # kommt aber nie in die bedingungen rein, und hab trotzdem das problem mit negativen werten\n",
    "    c1 = np.zeros((datapoints,1))\n",
    "    c2 = np.zeros((datapoints,1))\n",
    "    for i in np.arange(datapoints):\n",
    "        if (1/cav_diagV[i] == 1/Cumul[i,1]):\n",
    "            c2[i] = 1e-4\n",
    "        else:\n",
    "            c2[i] = (1 / Cumul[i,1]) - (1 / cav_diagV[i])\n",
    "\n",
    "     \n",
    "    for k in np.arange(datapoints):\n",
    "        if((1/c2[k] == np.infty) and (1/cav_diagV[k] == 0 or gauss_m[k] == cav_m[k])):\n",
    "            c1[k] = cav_m[k] * cav_diagV[k]\n",
    "        else:\n",
    "            c1[k] = Cumul[k,0] / Cumul[k,1] - cav_m[k] / cav_diagV[k]\n",
    "\n",
    "    for j in np.arange(datapoints):\n",
    "        if (1/c2[j] + cav_diagV[j]) < 0:\n",
    "            c1[j] = Term[j,0]\n",
    "            c2[j] = Term[j,1]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "            \n",
    "    TermNew = np.concatenate((c1, c2), axis=1)\n",
    "    TermNew = np.multiply(Term, (1 - eps_damp)) + np.multiply(TermNew, eps_damp)\n",
    "\n",
    "    \n",
    "    return TermNew, logZterms, logZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rasmussen Appendix 3.9**    \n",
    "\n",
    "$\\Phi(f(x)) = \\frac{1}{2} (1 + erf( x / \\sqrt{2} )) $  \n",
    "\n",
    "\n",
    "**Here** multiplication with true observation values:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logprobitpow(X, p, q):\n",
    "    \"\"\"\n",
    "    Compute ncdflogbc for matrices -> log of standard normal cdf by 10th order Taylor expansion in the negative domain\n",
    "    log likelihood evaluations for various probit power likelihoods\n",
    "    \n",
    "    Args:\n",
    "        X: matrix (datapoints,96)\n",
    "        p: number of runs satisfying property for each parameter, repeated (datapoints,96)\n",
    "        q: number of runs not satisfying property, repeated (datapoints,96)\n",
    "        \n",
    "    Returns:\n",
    "        Za+Zb:\n",
    "    \"\"\"\n",
    "    \n",
    "    threshold = -np.sqrt(2)*5\n",
    "    Za = []\n",
    "    y = []\n",
    "    j = 0\n",
    "    for x in X:\n",
    "        y.append([])\n",
    "        #print(x)\n",
    "        for i in x:\n",
    "            if i >= 0:\n",
    "                y[j].append(np.log(1 + erf(i/np.sqrt(2))) - np.log(2))\n",
    "            elif ((threshold < i) and (i < 0)):\n",
    "                y[j].append(np.log(1 - erf((-i)/np.sqrt(2))) - np.log(2))\n",
    "            elif i <= threshold:\n",
    "                y[j].append(-1/2 * np.log(np.pi) - np.log(2) - 1/2 * (-i) * (-i) - \\\n",
    "                np.log((-i)) + np.log(1 - 1/(-i) + 3/((-i)**4) - 15/((-i)**6) + 105/((-i)**8) - 945/((-i)**10)))\n",
    "        j+=1\n",
    "    #print(y)\n",
    "    Za = np.multiply(y, numpy.matlib.repmat(p.reshape(-1,1), 1, 96))\n",
    "\n",
    "    Zb = []\n",
    "    y = []\n",
    "    j = 0\n",
    "    for x in (-X):\n",
    "        y.append([])\n",
    "        #print(x)\n",
    "        for i in x:\n",
    "            #print(i)\n",
    "            if i >= 0:\n",
    "                y[j].append(np.log(1 + erf(i/np.sqrt(2))) - np.log(2))\n",
    "            elif ((threshold < i) and (i < 0)):\n",
    "                y[j].append(np.log(1 - erf((-i)/np.sqrt(2))) - np.log(2))\n",
    "            elif i <= threshold:\n",
    "                y[j].append(-1/2 * np.log(np.pi) - np.log(2) - 1/2 * (-i) * (-i) - \\\n",
    "                np.log((-i)) + np.log(1 - 1/(-i) + 3/((-i)**4) - 15/((-i)**6) + 105/((-i)**8) - 945/((-i)**10)))\n",
    "        j+=1\n",
    "\n",
    "    Zb = np.multiply(y, numpy.matlib.repmat(q.reshape(-1,1), 1, 96))\n",
    "    return Za + Zb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data (number of runs satisfying property):  [[5. 5. 4. 5. 5. 5. 5. 3. 3. 3. 4. 0. 4. 1. 3. 0. 2. 2. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "## configuration and data\n",
    "\n",
    "simulation_runs = scale = 5  # number of trajectories per input point\n",
    "paramValueSet = np.linspace(0.5, 5, 20).reshape(-1,1) # uncertain input parameter that is varied = population size\n",
    "datapoints = len(paramValueSet)  # number of input points\n",
    "paramValueOutputs = np.array([1,1,0.8,1,1,1,1,0.6,0.6,0.6,0.8,0,0.8,0.2,0.6,0,0.4,0.4,0,0.2]).reshape(-1,1) # statistical outputs of satisfaction \n",
    "data = trainingSet = [paramValueSet, paramValueOutputs] # set as training set for GP\n",
    "\n",
    "correction = 1e-4\n",
    "\n",
    "# plot training data\n",
    "plt.scatter(paramValueSet, paramValueOutputs, marker='o', c='blue')\n",
    "plt.title(f'Training dataset with {simulation_runs} trajectories per input point')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('Satisfaction probability')\n",
    "plt.yticks([0, 1])\n",
    "plt.show()\n",
    "\n",
    "print(\"Actual data (number of runs satisfying property): \", (paramValueOutputs * scale).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure is repeated until convergence = all marginal distributions $q(f_i)$ are consistent with $\\hat{p}(f_i)$  \n",
    "\n",
    "Normally you iterate through all data points, but here you just take them all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 96)\n",
      "Iteration  1\n",
      "(20, 96)\n",
      "Iteration  2\n",
      "(20, 96)\n",
      "Iteration  3\n",
      "(20, 96)\n",
      "Iteration  4\n",
      "(20, 96)\n",
      "Iteration  5\n",
      "(20, 96)\n",
      "Iteration  6\n",
      "(20, 96)\n",
      "Iteration  7\n",
      "(20, 96)\n",
      "Iteration  8\n",
      "(20, 96)\n",
      "Iteration  9\n",
      "(20, 96)\n",
      "Iteration  10\n",
      "(20, 96)\n",
      "Iteration  11\n",
      "(20, 96)\n",
      "Iteration  12\n",
      "(20, 96)\n",
      "Iteration  13\n",
      "(20, 96)\n",
      "Iteration  14\n",
      "(20, 96)\n",
      "Iteration  15\n",
      "(20, 96)\n",
      "Iteration  16\n",
      "(20, 96)\n",
      "Iteration  17\n",
      "(20, 96)\n",
      "Iteration  18\n",
      "(20, 96)\n",
      "Iteration  19\n",
      "(20, 96)\n",
      "Iteration  20\n",
      "(20, 96)\n",
      "Iteration  21\n",
      "(20, 96)\n",
      "Iteration  22\n",
      "(20, 96)\n",
      "Iteration  23\n",
      "(20, 96)\n",
      "Iteration  24\n",
      "(20, 96)\n",
      "Iteration  25\n",
      "\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "# initialization (all 0)\n",
    "# Prior\n",
    "gauss_C = kernel_rbf(paramValueSet, paramValueSet, params) + correction * np.eye(datapoints) # covariance training set\n",
    "\n",
    "gauss_LC_t = cholesky(gauss_C)  # cholesky decomposition, returns A=U'*U\n",
    "gauss_LC = gauss_LC_t.T  # transpose L' \n",
    "gauss_LC_diag = np.diagonal(gauss_LC).reshape(-1,1)\n",
    "\n",
    "logdet_LC = 2*np.sum(np.log(gauss_LC_diag))\n",
    "logZprior = 0.5*logdet_LC\n",
    "\n",
    "logZterms = np.zeros(datapoints).reshape(-1,1)\n",
    "logZloo = np.zeros(datapoints).reshape(-1,1)\n",
    "Term = np.zeros((datapoints, 2))  # Term = v_tilde, tau_tilde\n",
    "\n",
    "# compute marginal moments mu and sigma^2\n",
    "logZappx, gauss_m, gauss_diagV = marginal_moments(Term, gauss_LC, gauss_LC_t)\n",
    "\n",
    "# related to likelihood approximation\n",
    "# true observation values (number of trajectories satisfying property)\n",
    "gauss_LikPar_p = paramValueOutputs * scale\n",
    "gauss_LikPar_q = scale - gauss_LikPar_p \n",
    "\n",
    "# gauss hermite: quadrature to approximate values of integral, returns abscissas (x) and weights (w) of\n",
    "# n-point Gauss-Hermite quadrature formula\n",
    "nodes = 96\n",
    "gauss_xGauss, gauss_wGauss = gausshermite(nodes)\n",
    "gauss_logwGauss = np.log(gauss_wGauss)\n",
    "\n",
    "# configurations for loop initialization\n",
    "MaxIter=1000\n",
    "tol=1e-6\n",
    "logZold=0\n",
    "logZ = 2*tol\n",
    "steps=0\n",
    "logZappx=0\n",
    "eps_damp=0.5\n",
    "\n",
    "while (np.abs(logZ-logZold)>tol) and (steps<MaxIter):\n",
    "    steps += 1\n",
    "    logZold = logZ\n",
    "    \n",
    "    # find cavity distribution parameters mu_-i and sigma^2_-i\n",
    "    cav_m, cav_diagV = cavities(gauss_diagV, gauss_m, Term)\n",
    "    \n",
    "    # update marginal moments mu_hat and sigma^2_hat, and site parameters v_tilde and tau_tilde\n",
    "    Term, logZterms, logZloo = ep_update(cav_diagV, cav_m, Term, eps_damp, gauss_LikPar_p,\n",
    "                      gauss_LikPar_q, gauss_xGauss, gauss_logwGauss)\n",
    "    \n",
    "    # recompute mu and sigma^2 from the updated parameters\n",
    "    logZappx, gauss_m, gauss_diagV = marginal_moments(Term, gauss_LC, gauss_LC_t)\n",
    "    \n",
    "    logZ = logZterms.sum() + logZappx\n",
    "    \n",
    "    print(\"Iteration \", steps)\n",
    "    \n",
    "print(\"\\nFinish\")\n",
    "    \n",
    "    \n",
    "logZ = logZ - logZprior\n",
    "gauss_logZloo = logZloo.sum()\n",
    "gauss_logZappx = logZappx\n",
    "gauss_logZterms = logZterms\n",
    "gauss_logZ = logZ\n",
    "gauss_Term = Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish Training  \n",
    "\n",
    "$\\tilde{\\mu} = \\tilde{v} * \\frac{1}{\\tilde{\\tau}} $  \n",
    "\n",
    "$\\tilde{\\Sigma}$ with diagonal $\\tilde{\\Sigma}_{ii} = \\tilde{\\sigma}^2$  \n",
    "\n",
    "$invC = (C + \\tilde{\\Sigma})^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tilde = gauss_Term[:,0].reshape(-1,1)\n",
    "tau_tilde = gauss_Term[:,1].reshape(-1,1)\n",
    "\n",
    "diagSigma_tilde = 1/tau_tilde\n",
    "\n",
    "mu_tilde = np.multiply(v_tilde, diagSigma_tilde)\n",
    "\n",
    "Sigma_tilde = np.zeros((datapoints, datapoints))\n",
    "np.fill_diagonal(Sigma_tilde, diagSigma_tilde)\n",
    "\n",
    "# inverse of K + Sigma_tilde\n",
    "invC = np.linalg.solve((gauss_C + Sigma_tilde), np.eye(len(mu_tilde)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get GP Posterior\n",
    "\n",
    "\n",
    "**Rasmussen 3.60, 3.61**  \n",
    "\n",
    "Predictive mean for latent variable $f_*$: $\\mathbb{E}_q[f_*|X,y,x_*] = k_*^T (K + \\tilde{\\Sigma})^{-1} \\tilde{\\mu}$   \n",
    "\n",
    "Predictive variance: $\\mathbb{V}_q[f_*|X,y,x_*] = k(x_*,x_*) - k_*^T (K + \\tilde{\\Sigma})^{-1} k_*$  \n",
    "\n",
    "\n",
    "**Here:**  \n",
    "\n",
    "$fs = (ks (C + \\tilde{\\Sigma})^{-1}) \\tilde{\\mu}$  \n",
    "\n",
    "$vfs = kss - (ks (C + \\tilde{\\Sigma})^{-1} ) * ks^T$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define test set for which posterior is derived\n",
    "#testpoints = X_s = np.linspace(0, 20, 100).reshape(-1,1)\n",
    "testpoints = X_s = np.linspace(0, 5, 100).reshape(-1,1)\n",
    "\n",
    "\n",
    "# calculate variances of testset and covariances of test & training set (apply kernel)\n",
    "kss = kernel_rbf(testpoints, testpoints, params) #+ correction * np.eye(testpoints) \n",
    "ks = kernel_rbf(testpoints, paramValueSet, params) #+ correction * np.eye(datapoints)\n",
    "\n",
    "\n",
    "# predictive mean \n",
    "fs = np.matmul(np.matmul(ks, invC), mu_tilde)\n",
    "#fs = ks.T.dot(np.linalg.solve(invC.T, np.linalg.solve(invC, mu_tilde)))\n",
    "\n",
    "# predictive variance -> here only diagonal\n",
    "\n",
    "vfs = (np.diagonal(kss) - (np.diagonal(np.matmul(np.matmul(ks, invC), ks.T)))).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probit Regression Posterior\n",
    "Compute confidence bounds and plot results  \n",
    "\n",
    "\n",
    "**Rasmussen 3.63**   \n",
    "\n",
    "Predictive probability $q(y_*=1|X,y,x_*) = \\phi(\\frac{\\mathbb{E}_q[f_*|X,y,x_*]}{\\sqrt{1 + \\mathbb{V}_q[f_*|X,y,x_*]}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to compute probit values\n",
    "def standardNormalCDF(x):\n",
    "    return 1/2 + 1/2 * erf(x * (1/np.sqrt(2)))\n",
    "\n",
    "\n",
    "cached_denominator = (1 / np.sqrt(1 + vfs)).reshape(-1,1)\n",
    "\n",
    "\n",
    "# get probabilities with probit function\n",
    "probabilities = standardNormalCDF(fs * cached_denominator)\n",
    "\n",
    "\n",
    "# compute confidence bounds\n",
    "lowerbound = standardNormalCDF((fs - 1.96 * np.sqrt(vfs).reshape(-1,1)) *\n",
    "                              cached_denominator)\n",
    "upperbound = standardNormalCDF((fs + 1.96 * np.sqrt(vfs).reshape(-1,1)) *\n",
    "                              cached_denominator)\n",
    "\n",
    "# plot data\n",
    "plt.plot(testpoints, probabilities, lw=1.5, ls='-')\n",
    "plt.fill_between(testpoints.ravel(), lowerbound.ravel(), upperbound.ravel(), alpha=0.2)\n",
    "plt.scatter(paramValueSet, paramValueOutputs, marker='o', c='blue')\n",
    "plt.title(f'Classification with {scale} observations per input point')\n",
    "plt.xlabel('Population size $N$')\n",
    "plt.ylabel('Satisfaction probability')\n",
    "#plt.yticks([0, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
